# ğŸš€ Scalable Job Importer with Queue Processing & History Tracking

## ğŸ”— Live Deployments

- **Frontend (Vercel):** https://job-tracker-mauve.vercel.app/
- **Backend (Render â€“ Docker):** https://job-tracker-lkci.onrender.com

---

## ğŸ“Œ Objective

This project implements a **scalable job import system** that fetches jobs from an external API (XML feeds), processes them asynchronously using **Redis queues**, stores them in **MongoDB**, and tracks detailed **import history** with **Next.js admin UI**.

---

## ğŸ—ï¸ Tech Stack

### Frontend

- Next.js
- TypeScript
- Tailwind CSS

### Backend

- Node.js
- Express.js
- MongoDB (Mongoose)
- BullMQ (Queue)
- Redis

---

## âš™ï¸ Backend Setup

### âœ… System Requirements

- Node.js (>=18)
- npm
- MongoDB (Local or Atlas)
- Redis (Local or Cloud)
- Docker (Optional)

---

### ğŸ“¦ Install Dependencies

```bash
cd server
npm install
```

---

### ğŸ” Environment Variables

Create a `.env` file inside the `server` folder:

```env
PORT=5050

# Your databse connection uri (cloud or local)
MONGODB_URI="mongodb://localhost:27017/job-tracker"
NODE_ENV="dev" or "production"

# your redis cloud credentials:
REDIS_HOST="your-redis-host"
REDIS_PORT="your-redis-port" or 6379
REDIS_PASSWORD="your-redis-password"

WORKER_CONCURRENCY=10
JOB_IMPORT_CRON_TIME="0 * * * *"
JOB_BATCH_SIZE=10000
```

---

### â–¶ï¸ Run Backend Server (Without Docker)

```bash
npm run start
```

You should see logs for:

- MongoDB connection
- Redis connection
- Worker started with concurrency

Server runs at:

```
http://localhost:5050
```

---

### ğŸ³ Run Backend (With Docker)

> âš ï¸ Use Docker when docker is running on your system and we have **MongoDB Atlas / Cloud URI**

```bash
docker compose up -d
```

Check logs:

```bash
docker compose logs -f app
```

---

## ğŸŒ Backend APIs

### Get Import History

```
GET /importLog/
```

Example:

```
http://localhost:5050/importLog/
```

---

### Trigger Import Manually

```
POST /importJobs/
```

Example:

```
http://localhost:5050/importJobs/
```

---

## ğŸ¨ Frontend Setup

### ğŸ“¦ Install Dependencies

```bash
cd client
npm install
```

---

### ğŸ” Environment Variables

Create `.env` inside `client` folder:

```env
NEXT_PUBLIC_SERVER_ENDPOINT="http://localhost:5050"
```

---

### â–¶ï¸ Build & Start

```bash
npm run build
npm run start
```

Frontend runs at:

```
http://localhost:3000
```

---

## ğŸ§ª Testing the System

### Cron-Based Import

- Default cron runs **every hour**
- Change to every minute for testing:

```env
JOB_IMPORT_CRON_TIME="* * * * *"
```

Restart backend after change.

---

### Manual Import

Use Postman:

```
POST http://localhost:5050/importJobs/
```

---

## ğŸ“Š Import History Tracking

Displayed in UI with:

- Pagination
- Sorting
- Filters (date, status)

---

## âœ… Assumptions

- Job uniqueness determined by job ID
- Redis persistence handled by provider
- Read-heavy admin dashboard


---

### ğŸ‘¨â€ğŸ’» Author

**Aman Singh**
